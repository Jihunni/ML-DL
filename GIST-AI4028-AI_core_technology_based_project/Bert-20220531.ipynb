{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "- How to cleave the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4 MB 40.1 MB/s eta 0:00:01   |███▍                            | 2.1 MB 479 kB/s eta 0:00:37\n",
      "\u001b[?25hCollecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
      "\u001b[K     |████████████████████████████████| 453 kB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from konlpy) (1.20.3)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from konlpy) (4.6.3)\n",
      "Installing collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: mxnet in /usr/local/lib/python3.8/dist-packages (1.7.0.post1)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (1.19.5)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (2.25.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2.9)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gluonnlp in ./.local/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.55.1)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.8/site-packages (from gluonnlp) (21.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (1.19.5)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (0.29.13)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->gluonnlp) (2.4.6)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.94)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.8/site-packages (4.19.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.55.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in ./.local/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2020.2.20)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in ./.local/lib/python3.8/site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (2.4.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.7.1+cu110)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (3.7.4.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install mxnet\n",
    "# !pip install gluonnlp pandas tqdm\n",
    "# !pip install sentencepiece\n",
    "# !pip install transformers\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting kobert_tokenizer\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-wc2f0lq0/kobert-tokenizer_c8334ac4ce3741518a4c6a241b93439d\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-wc2f0lq0/kobert-tokenizer_c8334ac4ce3741518a4c6a241b93439d\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit e1f2f37055e7460d8427f6912579c0162cb69831\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  1 22:00:00 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.54       Driver Version: 510.54       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:D8:00.0 Off |                  N/A |\n",
      "| 46%   64C    P2   314W / 350W |   6721MiB / 24576MiB |     74%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     29078      C   python                           6719MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://github.com/naver/nlp-challenge/blob/master/missions/ner/data/train/train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/train_data.txt', sep='\\t',  header=None)\n",
    "# data.columns = ['index' , 'content', 'tag']\n",
    "# data['word_id'] = [k for k in range(len(data['content']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/indexingFile.csv', sep=',',  header=0)\n",
    "# data.columns = ['number', 'index' , 'content', 'tag']\n",
    "# data = data.drop(['number'], axis=1)\n",
    "# data['word_id'] = [k for k in range(len(data['content']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/indexingFile_527.csv', sep=',',  header=0)\n",
    "data.columns = ['number', 'index' , 'content', 'tag']\n",
    "data = data.drop(['number'], axis=1)\n",
    "data['word_id'] = [k for k in range(len(data['content']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>tag</th>\n",
       "      <th>word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>강사</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>로</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>활동</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>잘할</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>같은</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>일타</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>강사</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>로</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>같은</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>일타</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>강사</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>하면</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>스타는?.</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>일타</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>강사</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>로</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>하면</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>것</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>커피</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>커피</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>갤러</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>커피</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>리</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>커피</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>리</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index content  tag  word_id\n",
       "0       1      강사    1        0\n",
       "1       2       로    0        1\n",
       "2       3      활동    0        2\n",
       "3       4      잘할    0        3\n",
       "4       5      같은    0        4\n",
       "5       1      일타    0        5\n",
       "6       2      강사    1        6\n",
       "7       3       로    0        7\n",
       "8       4      같은    0        8\n",
       "9       1      일타    0        9\n",
       "10      2      강사    1       10\n",
       "11      3      하면    0       11\n",
       "12      4   스타는?.    0       12\n",
       "13      1      일타    0       13\n",
       "14      2      강사    1       14\n",
       "15      3       로    0       15\n",
       "16      4      하면    0       16\n",
       "17      5       것    0       17\n",
       "18      1      커피    1       18\n",
       "19      1      커피    1       19\n",
       "20      2      갤러    0       20\n",
       "21      1      커피    1       21\n",
       "22      2       리    0       22\n",
       "23      1      커피    1       23\n",
       "24      2       리    0       24"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split by a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_split = []\n",
    "tag_split = []\n",
    "word_id_split = []\n",
    "\n",
    "content_spliter = []\n",
    "tag_spliter = []\n",
    "word_spliter = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    content_spliter.append(data['content'].iloc[i])\n",
    "    tag_spliter.append(data['tag'].iloc[i])\n",
    "    word_spliter.append(data['word_id'].iloc[i])\n",
    "    if (i == len(data)-1) : # the last word in a data\n",
    "        content_split.append(content_spliter)\n",
    "        content_spliter = []\n",
    "        tag_split.append(tag_spliter)\n",
    "        tag_spliter = []\n",
    "        word_id_split.append(word_spliter)\n",
    "        word_spliter = []\n",
    "    elif (data['index'].iloc[i+1] == 1) : # the last word in a sentence\n",
    "        content_split.append(content_spliter)\n",
    "        content_spliter = []\n",
    "        tag_split.append(tag_spliter)\n",
    "        tag_spliter = []\n",
    "        word_id_split.append(word_spliter)\n",
    "        word_spliter = []\n",
    "        \n",
    "# sanity check\n",
    "len(content_split) == len(tag_split) == len(word_id_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703464"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703464"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703464"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_id_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "konlpy tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석 : ['자연어', '처리', '연구', '를', '기반', '으로', '인공', '지능', '모델', '을', '구성', '하고', '있습니다', '.']\n",
      "품사 태깅 : [('자연어', 'Noun'), ('처리', 'Noun'), ('연구', 'Noun'), ('를', 'Josa'), ('기반', 'Noun'), ('으로', 'Josa'), ('인공', 'Noun'), ('지능', 'Noun'), ('모델', 'Noun'), ('을', 'Josa'), ('구성', 'Noun'), ('하고', 'Josa'), ('있습니다', 'Adjective'), ('.', 'Punctuation')]\n",
      "명사 추출 : ['자연어', '처리', '연구', '기반', '인공', '지능', '모델', '구성']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "print('형태소 분석 :',okt.morphs(\"자연어 처리 연구를 기반으로 인공지능 모델을 구성하고 있습니다.\"))\n",
    "print('품사 태깅 :',okt.pos(\"자연어 처리 연구를 기반으로 인공지능 모델을 구성하고 있습니다.\"))\n",
    "print('명사 추출 :',okt.nouns(\"자연어 처리 연구를 기반으로 인공지능 모델을 구성하고 있습니다.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the vocabulary corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21057\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5498/251542825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtokenizer_voca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_voca\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to select the unique token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_voca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_voca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# to select unique value in content_split\n",
    "unique_content_list = list(set([x for sublist in content_split for x in sublist]))\n",
    "\n",
    "# to select only string\n",
    "filtered = filter(lambda voca: isinstance(voca, str), unique_content_list)\n",
    "unique_filtered_content_list = list(filtered)\n",
    "\n",
    "# concatenation for tokenizer\n",
    "unique_filtered_content_str = ' '.join(unique_filtered_content_list)\n",
    "\n",
    "# select nouns in order to reduce the number of tokens in the vocabulary corpus\n",
    "tokenizer_voca = okt.nouns(unique_filtered_content_str)\n",
    "tokenizer_voca = list(set(tokenizer_voca)) # to select the unique token\n",
    "print(len(tokenizer_voca))\n",
    "print(tokenizer_voca[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21057"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['락다운', '백지', '다이브', '언론사', '마렵구', '창작', '친척', '이빨', '다반', '카폐']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_voca[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21062\n",
      "21062\n",
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "del voca2idex, idex2voca\n",
    "voca2idex = {word: idx+5 for idx, word in enumerate(tokenizer_voca)}\n",
    "voca2idex['<unk>']= 0 # unknown\n",
    "voca2idex['<pad>']= 1 # padding\n",
    "voca2idex['<bos>']= 2 # begining of sentence\n",
    "voca2idex['<eos>']= 3 # end of sentence\n",
    "voca2idex['<mask>']= 4 # masking\n",
    "\n",
    "# configuration parameters\n",
    "VOCA_SIZE = len(voca2idex)\n",
    "print(VOCA_SIZE)\n",
    "\n",
    "# index2voca\n",
    "idex2voca = {v:k for k,v in voca2idex.items()}\n",
    "#print(list(gene2idex.keys())[list(gene2idex.values()).index(16)]) \n",
    "print(len(idex2voca))\n",
    "print(f'{idex2voca[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voca to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스푼'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idex2voca[21061]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3361"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voca2idex['멋대로']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3361, 0]\n"
     ]
    }
   ],
   "source": [
    "# seq_to_index function\n",
    "def sequence_to_index(string_list, voca2idex):\n",
    "    '''\n",
    "    INPUT\n",
    "        string_list : string list\n",
    "    OUTPUT\n",
    "        integer list\n",
    "    '''\n",
    "    converted_index = [voca2idex[word] if word in voca2idex.keys() else voca2idex['<unk>'] for word in string_list]\n",
    "    return converted_index\n",
    "\n",
    "# example\n",
    "print(sequence_to_index(['멋대로', '가나다라마'], voca2idex)) # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## tag integer encodding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list = data['tag'].unique()\n",
    "num_tags = len(tag_list)\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag2idex = {tag: idx for idx, tag in enumerate(tag_list)}\n",
    "# tag2idex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "idex2tag = {}\n",
    "idex2tag[0]='<unk>'\n",
    "idex2tag[1]='<pad>'\n",
    "idex2tag[2]='<bos>'\n",
    "idex2tag[3]='<eos>'\n",
    "idex2tag[4]='<mask>'\n",
    "idex2tag[5]='non'\n",
    "idex2tag[6]='coffe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idex = {'<unk>':0,'<pad>':1,'<bos>':2,'<eos>':3,'<mask>':4, 0:5, 1:6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "# seq_to_index function\n",
    "def tag_to_index(sequence, embedding_index):\n",
    "    '''\n",
    "    INPUT\n",
    "        sequence : string list\n",
    "    OUTPUT\n",
    "        integer list\n",
    "    '''\n",
    "    converted_index = [embedding_index[word] if word in embedding_index.keys() else embedding_index['<unk>'] for word in sequence]\n",
    "    return converted_index\n",
    "\n",
    "# # index2gene\n",
    "# idex2tag = {v:k for k,v in tag2idex.items()}\n",
    "# idex2tag[0]='[UNK]'\n",
    "# idex2tag[1]='[PAD]'\n",
    "# idex2tag[2]='[CLS]'\n",
    "# idex2tag[3]='[SEP]'\n",
    "# idex2tag[4]='[MASK]'\n",
    "# #print(list(gene2idex.keys())[list(gene2idex.values()).index(16)]) \n",
    "# print(f'{idex2tag[1]}')\n",
    "\n",
    "print(tag_to_index(['5', '6'], tag2idex)) # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_to_index(['PER_B', 'DAT_B'], tag2idex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/voca2idex.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(voca2idex, fw)\n",
    "with open(\"data/idex2voca.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(idex2voca, fw)    \n",
    "with open(\"data/tag2idex.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(tag2idex, fw)\n",
    "with open(\"data/idex2tag.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(idex2tag, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_tokenizer = []\n",
    "# word_id_tokenizer = []\n",
    "# tag_id_tokenizer = []\n",
    "# label_ids_tokenizer = []\n",
    "# for i in data['word_id'][0:50]:\n",
    "#     # tokenizer\n",
    "#     content_tokenizer += tokenizer.encode(data['content'].iloc[i])[1:-1]\n",
    "#     word_id_tokenizer += [i]*(len(tokenizer.encode(data['content'].iloc[i]))-2)    \n",
    "#     label_ids_tokenizer += [tag2idex[data['tag'].iloc[i]]] + [-100] * (len(tokenizer.encode(data['content'].iloc[i]))-3)\n",
    " \n",
    "    \n",
    "# data_tokenizer = pd.DataFrame({'token': content_tokenizer, 'word_id': word_id_tokenizer, 'label_ids': label_ids_tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = okt.morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def tokenizer_per_sentece(content_list, tag_list, word_id_list):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        content_split_list : a list that represents a sentence \n",
    "            e.g. ['비토리오', '양일', '만에', '영사관', '감호', '용퇴,', '항룡', '압력설', '의심만', '가율']\n",
    "        tag_split_list\n",
    "            e.g. ['PER_B', 'DAT_B', '-', 'ORG_B', 'CVL_B', '-', '-', '-', '-', '-']\n",
    "        word_id_split_list\n",
    "            e.g. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    OUTPUT: tokenzier results\n",
    "        content_tokenizer : a tokenized content list without special tokens\n",
    "        word_id_tokenizer : a word id list\n",
    "        tag_id_tokenizer : a tag id list that the only first content has a tag.\n",
    "    \"\"\"\n",
    "    # sanity check\n",
    "    if not (len(content_list)==len(tag_list)==len(word_id_list)):\n",
    "        print(\"check the input data\")\n",
    "    \n",
    "    # tokenizer\n",
    "    content_tokenizer = []\n",
    "    word_id_tokenizer = []\n",
    "    tag_id_tokenizer = []\n",
    "    \n",
    "    # error handling : nan in input\n",
    "    if any(pd.isna(content_list)):\n",
    "        return [], [], []\n",
    "    \n",
    "    for i in range(len(word_id_list)):\n",
    "        # tokenizer\n",
    "        content_tokenizer += tokenizer(content_list[i]) # to remove special tokens [CLS] and [SEP]\n",
    "        word_id_tokenizer += [word_id_list[i]] * (len(tokenizer(content_list[i])))\n",
    "        tag_id_tokenizer += [tag2idex[tag_list[i]]] + [-100] * (len(tokenizer(content_list[i]))-1)\n",
    "    \n",
    "    # to convert string into index\n",
    "    content_tokenizer = sequence_to_index(content_tokenizer, voca2idex)\n",
    "    \n",
    "    # error handling : tokenizer does not work properly\n",
    "    if not (len(content_tokenizer) == len(word_id_tokenizer) == len(tag_id_tokenizer)):\n",
    "        # tokenzier does not work properly becuase of noise.\n",
    "        print(f'sanity check : {len(content_tokenizer) == len(word_id_tokenizer) == len(tag_id_tokenizer)}')\n",
    "        content_tokenizer = []\n",
    "        word_id_tokenizer = []\n",
    "        tag_id_tokenizer = []\n",
    "    return content_tokenizer, tag_id_tokenizer, word_id_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['강사', '로', '활동', '잘할', '같은']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = tokenizer_per_sentece(content_split[0], tag_split[0], word_id_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5227, 14215, 7432, 0, 9876, 0]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['강사', '로', '활동', '<unk>', '할', '<unk>']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idex2voca[word] for word in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5, 5, 5, -100, 5]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 3, 4]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['커피', '블렌드', '샀음', '500g', '아쉬움', '맛']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_split[172999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_split[172999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[509998, 509999, 510000, 510001, 510002, 510003]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id_split[172999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = tokenizer_per_sentece(content_split[172999], tag_split[172999], word_id_split[172999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[893, 2421, 0, 0, 0, 17302, 20449]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_split[500120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.isnan(content_split[500120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(content_split[500120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(content_split[500120][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = tokenizer_per_sentece(content_split[500120], tag_split[500120], word_id_split[500120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1', 'coffee', nan, 'Mp']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_split[598602]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(content_split[598602])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(pd.isna(content_split[598602]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = tokenizer_per_sentece(content_split[598602], tag_split[598602], word_id_split[598602])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def tokenizer_all_data(content_split, tag_split, word_id_split):\n",
    "    # sanity check\n",
    "    if not (len(content_split)==len(tag_split)==len(word_id_split)):\n",
    "        print(\"check the input data\")\n",
    "        \n",
    "    content_split_token, tag_split_token, word_id_split_token = [], [], []\n",
    "    for i in tqdm(range(len((content_split)))):\n",
    "        #print(i)\n",
    "        content, tag, wordID = tokenizer_per_sentece(content_split[i], tag_split[i], word_id_split[i])\n",
    "        content_split_token.append(content)\n",
    "        tag_split_token.append(tag)\n",
    "        word_id_split_token.append(wordID)\n",
    "    return content_split_token, tag_split_token, word_id_split_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 703464/703464 [1:11:04<00:00, 164.96it/s]\n"
     ]
    }
   ],
   "source": [
    "content_split_tok, tag_split_tok, word_id_split_tok = tokenizer_all_data(content_split, tag_split, word_id_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "record\n",
    "- 20220527 : KoBert\n",
    "- 20220531 : Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/content_split_tok_20220531.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(content_split_tok, fw)\n",
    "with open(\"data/tag_split_tok_20220531.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(tag_split_tok, fw)\n",
    "with open(\"data/word_id_split_tok_20220531.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(word_id_split_tok, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "with open(\"data/content_split_tok_20220531.pickle\", \"rb\") as fr:\n",
    "    content_split_tok = pickle.load(fr)\n",
    "with open(\"data/tag_split_tok_20220531.pickle\", \"rb\") as fr:\n",
    "    tag_split_tok = pickle.load(fr)\n",
    "with open(\"data/word_id_split_tok_20220531.pickle\", \"rb\") as fr:\n",
    "    word_id_split_tok = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['강', '사', '하면', '잘', '할', '스타', '는', '?', '.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "[tokenizer.decode(token) for token in content_split_tok[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653\n",
      "6.924360502429632\n"
     ]
    }
   ],
   "source": [
    "print(max([len(x) for x in content_split_tok]))\n",
    "print(sum([len(x) for x in content_split_tok])/len(content_split_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_tensor(token_list, max_len=512):\n",
    "    '''\n",
    "    This function get a list of token lists and converts a input list into a list in size of max_len including special tokens.\n",
    "    \n",
    "    INPUT\n",
    "        token_list : a list of token lists\n",
    "            e.g. [[1,2,3,4], [5,6,7,8], [9, 10, 11, 12, 13, 14, 15]]\n",
    "        max_len : int\n",
    "    OUTPUT\n",
    "        token_ls : a list of lists in size of max_len with special tokens. The last token that does not fit the size would be dropped.\n",
    "            e.g. [[0, 1, 2, 3, 4, 0], [0, 5, 6, 7, 8, 0], [0, 9, 10, 11, 12, 0]]\n",
    "    '''\n",
    "    # setting\n",
    "    max_len = max_len-2 # to consider the special tokens\n",
    "    pad = 1 # an index of special token\n",
    "    bos = 2 # an index of special token\n",
    "    eos = 3 # an index of special token\n",
    "    token_output_ls = []\n",
    "    token_ls = []\n",
    "    #token_ls_iter_position = 0 # index of the last element in token_ls\n",
    "    \n",
    "    for index, tokens in enumerate(token_list):\n",
    "        n_token = len(tokens)\n",
    "        \n",
    "        if len(token_ls) + n_token <= max_len :\n",
    "            token_ls += tokens\n",
    "            #token_ls_iter_position += len(token_ls)\n",
    "        else : \n",
    "            cut_position = max_len - len(token_ls)\n",
    "            #assert cut_position >= 0\n",
    "            token_ls += tokens[:cut_position]\n",
    "\n",
    "            # to collect the current token_ls\n",
    "            token_ls = [bos] + token_ls + [eos] # to add special tokens\n",
    "\n",
    "            if not len(token_ls)-2 == max_len : \n",
    "                print(f'index: {index}')\n",
    "                print(f'cut_position: {cut_position}')\n",
    "                print(len(token_ls))\n",
    "            assert len(token_ls)-2 == max_len\n",
    "            token_output_ls.append(token_ls)\n",
    "\n",
    "            # to update token_ls for next iteration\n",
    "            token_ls = tokens[cut_position:]\n",
    "            #token_ls_iter_position = len(token_ls) - 1\n",
    "            \n",
    "            # if token_ls is longer than max_len, it requires an additional cleavage\n",
    "            while (len(token_ls) > max_len):\n",
    "                token_output_ls.append([bos] + token_ls[:max_len] + [eos])\n",
    "                token_ls = tokens[max_len:]\n",
    "    return token_output_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_input = prep_for_tensor(content_split_tok, 512)\n",
    "tag_input = prep_for_tensor(tag_split_tok, 512)\n",
    "word_id_input = prep_for_tensor(word_id_split_tok, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[807, 6493, 517, 6079, 5141, 3942, 7836, 833]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_split_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4656]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_split_tok[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_padding(token_list, max_len=512):\n",
    "#     '''\n",
    "#     INPUT\n",
    "#         token_list : list\n",
    "#             e.g. [[1,2,3,4], [5,6,7,8]]\n",
    "#         max_len : int\n",
    "#     OUTPUT\n",
    "#         token_ls : list\n",
    "#     '''\n",
    "#     import copy\n",
    "#     token_ls = copy.deepcopy(token_list)\n",
    "#     max_len = max_len-2 # to consider the special tokens\n",
    "#     for index, tokens in enumerate(token_ls):\n",
    "#         n_token = len(tokens)\n",
    "#         pad = 1 # an index of special token\n",
    "#         bos = 2 # an index of special token\n",
    "#         eos = 3 # an index of special token\n",
    "#         # add padding if the length is shorter than max_len\n",
    "#         if n_token < max_len:\n",
    "#             token_ls[index] += [pad] * (max_len - n_token) # 부족한 만큼 padding을 추가함\n",
    "        \n",
    "#         # if a sentence is longer than max_len, cut a sentence.\n",
    "#         elif n_token > max_len:\n",
    "#             token_ls[index] = tokens[:max_len]\n",
    "        \n",
    "#         # to add begining token and end token\n",
    "#         token_ls[index] = [bos] + token_ls[index] + [eos]\n",
    "#     return token_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_input = add_padding(content_split_tok, 512)\n",
    "# tag_input = add_padding(tag_split_tok, 512)\n",
    "# word_id_input = add_padding(word_id_split_tok, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_input[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/content_input_20220531.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(content_input, fw)\n",
    "with open(\"./data/tag_input_20220531.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(tag_input, fw)\n",
    "with open(\"./data/word_id_input_20220531.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(word_id_input, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21062\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# to load dictionary corpus data\n",
    "with open(\"./data/voca2idex.pickle\", \"rb\") as fr:\n",
    "    voca2idex = pickle.load(fr)\n",
    "with open(\"./data/idex2voca.pickle\", \"rb\") as fr:\n",
    "    idex2voca = pickle.load(fr)\n",
    "with open(\"./data/tag2idex.pickle\", \"rb\") as fr:\n",
    "    tag2idex = pickle.load(fr)\n",
    "with open(\"./data/idex2tag.pickle\", \"rb\") as fr:\n",
    "    idex2tag = pickle.load(fr)\n",
    "\n",
    "# to load train data  \n",
    "with open(\"./data/content_input_20220531.pickle\", \"rb\") as fr:\n",
    "    content_input = pickle.load(fr)\n",
    "with open(\"./data/tag_input_20220531.pickle\", \"rb\") as fr:\n",
    "    tag_input = pickle.load(fr)\n",
    "with open(\"./data/word_id_input_20220531.pickle\", \"rb\") as fr:\n",
    "    word_id_input = pickle.load(fr)\n",
    "    \n",
    "# configuration parameters\n",
    "VOCA_SIZE = len(voca2idex)\n",
    "print(VOCA_SIZE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = torch.tensor(content_input)\n",
    "input_y = torch.tensor(tag_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,  5227, 14215,  7432,     0,  9876,     0, 19157,   608,  5227,\n",
       "        14215,     0, 19157,   608,  5227,     0,  2133,  3437,     0, 19157,\n",
       "          608,  5227, 14215,     0, 18031,   893,   893,     0,   893, 19029,\n",
       "          893, 19029,   893,   893,  3887,  6187,   893,   893,     0,   952,\n",
       "            0,  9864,  9864,  9864,  9864,  5556, 11745, 11745, 20368,  5556,\n",
       "        11745, 20368, 11745,    99,  4089,  8121, 20856, 18095,  4300,    99,\n",
       "         4089,  8121, 19546, 20856, 18095,  4300,    99,  4089,  8121, 20856,\n",
       "        18095,  4300,  5758,    99,  4089,  8121, 20856, 18095,  4300,  7182,\n",
       "          893,  5287,     0,  7182,   893,  5287,  7182, 13088,   893,  5287,\n",
       "         7182, 14129,   893,  5287,     0, 19314,     0,     0,  1685, 20670,\n",
       "            0,     0,     0,  1685,     0,  4415,     0,     0,     0,  1685,\n",
       "            0,  1685,  4415,  4415,   893,   893,   893,     0,   893,  1489,\n",
       "         6664,     0, 15034,  6664, 10242,  1489,  6664, 15034,  6664, 10242,\n",
       "            0,     0,     0,  1489,  6664, 15034,  6664, 10242,  1489,  6664,\n",
       "            0, 15034,  6664, 10242,     0,     0,     0,  6508,     0,  9248,\n",
       "         6508,     0,  9248, 14215,  1131,  8512,  6508,     0,  9248,   209,\n",
       "         6508,     0,  9248,     0,  2157,  4548,  2157,  4548,  2157,  2157,\n",
       "         4548,     0,     0,     0,     0,     0,     0,  3469, 11019,  1339,\n",
       "            0,     0,  2364,  7917,  5256,  9461,  6886,  7917,  5256,  9461,\n",
       "         6886, 15607,  7917,  5256,  9461,  6886,     0, 15607,  7917,  5256,\n",
       "            0,  9461,  6886,     0, 18159,   452, 18159,   452, 18979, 15703,\n",
       "        15703, 11691, 18979,  1278,     0,     0,     0,  1127,  9212,     0,\n",
       "            0,  1127,  9212,     0, 19157, 15253,   893, 19641, 15880, 19157,\n",
       "        15253,   893, 19641, 15880, 19157, 15253,   893, 19641, 15880,     0,\n",
       "        19157, 15253,   893, 19641, 15880,     0,     0, 20741,  1128, 20741,\n",
       "            0, 11888,     0,     0,     0, 14693, 13526,     0, 14693, 13526,\n",
       "            0,     0, 14693, 13526,     0,     0, 14693, 13526,  9588, 13048,\n",
       "        15349,     0, 11053, 11053,  6257,     0,     0, 11053,     0, 11053,\n",
       "        14334,  2421, 14734,     0,     0, 14334,  2421, 14734, 14334,  2421,\n",
       "        14734, 14334,  2421, 14734,     0,     0,  7182,  7182,  7182, 10837,\n",
       "         7182,  8368,   991,  6886,     0,  8368,   991,  8368,   991,     0,\n",
       "         8368,   991, 14582,  6886,     0,  7182,  5556,  2202, 14033,  4548,\n",
       "         7182, 13468, 13505, 14033,  7182,  5556,  2202, 14033,  1339,     0,\n",
       "         7182, 14033,  4548,     0,  6199,     0,     0,     0, 14734, 14734,\n",
       "        20430, 14734,  4415, 13794,  2341, 13794, 14734,  4415, 13794,  2341,\n",
       "        13794, 17091,     0,  6392,     0,     0,   893,     0,  7447,     0,\n",
       "          893,  7447,   893,  4037,  2236,  2202, 13468,  7447,   893,     0,\n",
       "         4037,  2236,  2202, 13468,  7447,  7182, 17890,  7182, 17890,  7182,\n",
       "        17890,  7182,     0, 17890,     0,     0, 12895,     0,   839,  9622,\n",
       "        20449, 20350, 12895,   839,  9622, 20449, 20350, 14215, 12895, 20449,\n",
       "        19803,  2236, 20350, 14215, 12895, 20449, 19803,  2236,     0,  4990,\n",
       "            0,     0,  4990, 12631, 14004,     0,  4990,   554,     0,  4068,\n",
       "         8368,     0, 14004,     0,  8368,     0,  8368,     0, 10051,  8368,\n",
       "            0, 10322,     0, 16002, 12003, 17209, 12003, 17209, 12003,     0,\n",
       "        17209, 16002, 12003,     0,     0,     0, 13468,     0,     0,     0,\n",
       "        13468, 14740,     0,     0,     0, 13468, 14740,     0,     0,     0,\n",
       "        14740,  7027,  7294,     0,   893,  8652, 11272,     0,     0,   893,\n",
       "         8652, 11272,     0,     0,     0,     0,   893,  6734,  8652, 11272,\n",
       "            0,     0,  7362, 11473,   893,     0,  8652, 11272,     0,     0,\n",
       "            0,     0,  7182,  2168, 14463,  7182,  2168, 14463, 15118,  7182,\n",
       "         2168, 14463,  7182,  2168, 14463, 15933, 15259,  7362, 15933, 15259,\n",
       "         7362,     3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,    5,    6,    6, -100,    6,    6, -100,    6,    6, -100,    6,\n",
       "           5,    6, -100,    5, -100, -100, -100,    5,    6,    5,    6,    5,\n",
       "           5,    6,    5,    5,    5, -100,    6,    5,    5,    5,    6,    6,\n",
       "           5, -100,    6,    6,    5, -100,    6,    6,    5, -100,    6,    6,\n",
       "           5, -100, -100,    5,    6,    5,    6,    5,    5,    6,    6,    5,\n",
       "           6,    6,    6,    5,    6,    5,    5,    6,    6,    5,    5,    6,\n",
       "           5,    5,    6,    6,    6,    5, -100, -100,    6,    6,    5,    5,\n",
       "        -100, -100,    6,    6,    5,    5, -100, -100,    5,    6,    6,    5,\n",
       "           5, -100, -100,    6,    6,    6,    6,    6,    5,    6,    6,    6,\n",
       "           6,    6,    6,    6,    6,    5, -100,    6,    6,    6,    6,    5,\n",
       "        -100,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
       "           5,    6,    5, -100,    5,    5, -100,    5,    6,    5, -100,    5,\n",
       "           6,    5,    5,    5,    6,    5,    6, -100,    6, -100,    6, -100,\n",
       "           6, -100,    5,    6,    6,    6,    5,    5,    6,    6,    5, -100,\n",
       "           6,    6,    6,    6,    6,    6,    6,    6,    5,    6,    6,    6,\n",
       "           6,    6,    6,    6,    5,    6,    6,    6,    6,    5,    6,    6,\n",
       "           5,    6,    6,    5,    5,    5, -100,    6,    6,    6,    6, -100,\n",
       "           6,    6,    6,    6,    6, -100,    6,    6,    6,    6,    5,    6,\n",
       "        -100,    6,    6,    5,    5, -100,    6,    6,    6, -100,    5,    6,\n",
       "           6, -100,    6,    6,    6, -100,    5,    5,    6,    6,    6, -100,\n",
       "           6,    6,    6, -100,    5,    6,    6,    5, -100, -100,    6,    6,\n",
       "           6,    6,    6,    6,    5, -100,    6,    6,    5, -100,    5, -100,\n",
       "        -100,    5, -100,    5,    5, -100, -100,    5, -100,    6, -100,    6,\n",
       "           5,    6,    5,    6, -100,    6,    6,    6, -100,    6,    6,    6,\n",
       "        -100,    6,    6,    5,    6, -100,    6,    6, -100,    5,    5,    5,\n",
       "           6,    5, -100,    6, -100,    6,    5, -100,    6, -100,    5,    6,\n",
       "           5, -100,    6,    5, -100,    6,    6,    5,    6,    5,    6,    5,\n",
       "        -100,    6,    6,    5, -100,    6,    6,    5, -100,    5, -100, -100,\n",
       "           6,    5,    5, -100, -100,    5, -100,    6,    5,    5, -100,    6,\n",
       "           5,    5,    5, -100,    6,    6, -100,    6,    6, -100,    6,    6,\n",
       "        -100,    5,    6,    6, -100,    6,    6,    6,    5,    6,    5,    5,\n",
       "           5,    5,    5,    5,    5,    5, -100,    5, -100,    5, -100,    5,\n",
       "        -100,    6,    5,    6,    6,    5,    6,    6,    6,    5,    6,    5,\n",
       "           5,    6,    5,    6,    6,    6,    5,    6,    6,    5,    6,    5,\n",
       "           6,    6,    6,    6,    6,    5,    6,    6,    6, -100,    6,    6,\n",
       "        -100,    6,    5,    6,    6, -100,    6,    6, -100,    6,    5, -100,\n",
       "           6,    6, -100,    6,    6, -100,    6,    5,    6,    6, -100,    5,\n",
       "           6,    6, -100,    6,    5,    5,    5,    5,    5,    6,    6,    6,\n",
       "           6,    6,    6,    5,    5,    5,    6,    5,    6,    6,    5,    6,\n",
       "           6,    6,    5,    5,    5, -100,    5, -100,    6,    6,    5,    6,\n",
       "           6,    6,    6,    5,    6,    5, -100, -100,    6,    5, -100,    5,\n",
       "        -100,    5,    5,    5, -100,    5,    5,    5,    5, -100,    5, -100,\n",
       "           6,    6, -100,    6,    5,    6,    6,    3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_y[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6064\n",
      "4851\n",
      "606\n",
      "607\n",
      "sanity check:  True\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size=8\n",
    "total_dataset = TensorDataset(input_x, input_y)\n",
    "\n",
    "num_train = int(len(total_dataset)*0.8)\n",
    "num_validation = int(len(total_dataset)*0.1)\n",
    "num_test = len(total_dataset)-num_train-num_validation\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(total_dataset, [num_train, num_validation, num_test])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "print(len(total_dataset))\n",
    "print(len(train_dataset))\n",
    "print(len(validation_dataset))\n",
    "print(len(test_dataset))\n",
    "print('sanity check: ', len(total_dataset)==len(train_dataset)+len(validation_dataset)+len(test_dataset))\n",
    "\n",
    "\n",
    "len(train_loader)\n",
    "len(validation_loader)\n",
    "len(test_loader)\n",
    "\n",
    "del total_dataset, num_train, num_validation, num_test, train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = seq_length = 512\n",
    "num_tag = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined_args = {\n",
    "#         'attention_cell': 'multi_head',\n",
    "#         'num_layers': 12,\n",
    "#         'units': 768, \n",
    "#         'hidden_size': 3072,\n",
    "#         'max_length': 512,\n",
    "#         'num_heads': 12,\n",
    "#         'scaled': True,\n",
    "#         'dropout': 0.1,\n",
    "#         'use_residual': True,\n",
    "#         'embed_size': 768,\n",
    "#         'embed_dropout': 0.1,\n",
    "#         'token_type_vocab_size': 2,\n",
    "#         'word_embed': None,\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder\n",
    "import math\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx= int(voca2idex['<pad>']))\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = max_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "\n",
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 num_labels=num_tag,\n",
    "                 max_length=max_length,\n",
    "                 dropout: float = 0.1):\n",
    "        super(BERT, self).__init__()\n",
    "        self.src_tok_emb = TokenEmbedding(vocab_size=src_vocab_size, emb_size=emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "                                                       dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.classifier = nn.Linear(emb_size, num_labels)\n",
    "        self.num_labels = num_labels\n",
    "        self.max_length = max_length\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                src_padding_mask: Tensor):\n",
    "        # print(f'src.size(): {src.size()}')\n",
    "        # print(f'src_tok_emb(src): {self.src_tok_emb(src)}')\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        # print('transformer src: ', src)\n",
    "        # print('transformer src_mask: ', src_mask)\n",
    "        # print('transformer src_mask.size(): ', src_mask.size())\n",
    "        # print('transformer src_padding_mask: ', src_padding_mask)\n",
    "        # print('transformer src_padding_mask.size(): ', src_padding_mask.size()) \n",
    "        # print('transformer src_emb: ', src_emb)\n",
    "        # print('transformer src_emb.size(): ', src_emb.size())\n",
    "        output = self.transformer_encoder(src=src_emb, mask=src_mask, src_key_padding_mask=src_padding_mask) \n",
    "            # [batch_size, max_length, emb_size]\n",
    "        # print('transformer_encoder output.size(): ', output.size())\n",
    "        output = self.dropout(output)\n",
    "        output = self.classifier(output) #[batch_size, max_length*num_label]\n",
    "        # print('classifier output.size(): ', output.size())\n",
    "        output = output.view([-1, self.num_labels, self.max_length]) # [batch_size, num_label, max_length]\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(size):\n",
    "    mask = (torch.triu(torch.ones((size, size), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src):\n",
    "    src_seq_len = src.shape[1] # src:  [batch_size, seq_length]\n",
    "    src_padding_mask = (src == voca2idex['<pad>'])\n",
    "    return src_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_square_subsequent_mask(size):\n",
    "#     mask = (torch.triu(torch.ones((size, size), device=DEVICE)) == 1).transpose(0, 1)\n",
    "#     mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "#     return mask\n",
    "\n",
    "# def create_mask(src, tgt):\n",
    "#     src_seq_len = src.shape[1] # src:  [batch_size, seq_length]\n",
    "#     tgt_seq_len = tgt.shape[1] # tgt: [batch_size, seq_length]\n",
    "\n",
    "#     tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "#     src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "#     src_padding_mask = (src == voca2idex['<pad>'])\n",
    "#     tgt_padding_mask = (tgt == voca2idex['<pad>'])\n",
    "    \n",
    "#     return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = VOCA_SIZE #21062\n",
    "EMB_SIZE = 512 # hidden # 512\n",
    "NHEAD = 8 # 8\n",
    "FFN_HID_DIM = 512  # 512\n",
    "BATCH_SIZE = batch_size\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "model = BERT(NUM_ENCODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, FFN_HID_DIM).to(DEVICE)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: \n",
      "torch.Size([8, 7, 512])\n",
      "tgt: torch.Size([8, 512])\n",
      "tensor(2.1009, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "for src, tgt in train_loader:\n",
    "    src = src.type(torch.LongTensor).to(DEVICE)\n",
    "    tgt = tgt.type(torch.LongTensor).to(DEVICE)\n",
    "    src_padding_mask = create_mask(src)\n",
    "    logits = model(src, None, src_padding_mask.to(DEVICE))\n",
    "    print('logits: ')\n",
    "    print(logits.size()) #[?, num_tags, seq_length]\n",
    "    print(f'tgt: {tgt.size()}') #[batch_size, seq_length]\n",
    "    loss = loss_fn(logits, tgt)\n",
    "    print(loss)\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, data_loader, max_length=max_length, DEVICE='cuda'):\n",
    "    import gc\n",
    "    from tqdm import tqdm\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    losses = 0\n",
    "    num_correct = []\n",
    "    num_test = 0\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    for src, tgt in data_loader:\n",
    "        src = src.type(torch.LongTensor).to(DEVICE) #[batch_size, seq_length]\n",
    "        tgt = tgt.type(torch.LongTensor).to(DEVICE) #[batch_size, seq_length]\n",
    "        src_padding_mask = create_mask(src)\n",
    "        logits = model(src, None, src_padding_mask)\n",
    "            #torch.Size([batch_size, , num_tag, src_seq_length])\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits, tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "        # accuracy\n",
    "        _, pred_word = torch.max(logits, dim=1)\n",
    "        num_correct.append(int((torch.flatten(tgt)==torch.flatten(pred_word)).sum()))\n",
    "        num_test += int(torch.flatten(pred_word).size(0))\n",
    "        \n",
    "    accuracy = sum(num_correct) / num_test\n",
    "    \n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    " \n",
    "    return losses / len(data_loader), accuracy\n",
    "\n",
    "\n",
    "def test_epoch(model, optimizer, data_loader, max_length=max_length, DEVICE='cuda'):\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        losses = 0\n",
    "        num_correct = []\n",
    "        num_test = 0\n",
    "        y_probability = np.array([])\n",
    "        y_pred = np.array([])\n",
    "        y_true = np.array([])\n",
    "        for src, tgt in data_loader:\n",
    "            src = src.type(torch.LongTensor).to(DEVICE) #[batch_size, seq_length]\n",
    "            tgt = tgt.type(torch.LongTensor).to(DEVICE) #[batch_size, seq_length]\n",
    "            src_padding_mask = create_mask(src)\n",
    "            logits = model(src, None, src_padding_mask)\n",
    "                #torch.Size([batch_size, , num_tag, src_seq_length])\n",
    "            \n",
    "            loss = loss_fn(logits, tgt)\n",
    "            losses += loss.item()\n",
    "            \n",
    "            # accuracy\n",
    "            _, pred_word = torch.max(logits, dim=1)\n",
    "            num_correct.append(int((torch.flatten(tgt)==torch.flatten(pred_word)).sum()))\n",
    "            num_test += int(torch.flatten(pred_word).size(0))\n",
    "            \n",
    "            y_probability = np.append(y_probability, logits.cpu().detach().numpy())\n",
    "            y_pred = np.append(y_pred, pred_word.cpu().detach().numpy())\n",
    "            y_true = np.append(y_true, tgt.cpu().detach().numpy())\n",
    "            \n",
    "    accuracy = sum(num_correct) / num_test\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return losses / len(data_loader), accuracy,  y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch_check(model, optimizer, data_loader, max_length=max_length, DEVICE='cuda'):\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        losses = 0\n",
    "        num_correct = []\n",
    "        num_test = 0\n",
    "        y_probability = np.array([])\n",
    "        y_pred = np.array([])\n",
    "        y_true = np.array([])\n",
    "        for src, tgt in tqdm(data_loader):\n",
    "            src = src.type(torch.LongTensor).to(DEVICE) #[batch_size, seq_length]\n",
    "            tgt = tgt.type(torch.LongTensor).to(DEVICE) #[batch_size, seq_length]\n",
    "            src_padding_mask = create_mask(src)\n",
    "            logits = model(src, None, src_padding_mask)\n",
    "                #torch.Size([batch_size, , num_tag, src_seq_length])\n",
    "            \n",
    "            loss = loss_fn(logits, tgt)\n",
    "            losses += loss.item()\n",
    "            \n",
    "            # accuracy\n",
    "            _, pred_word = torch.max(logits, dim=1)\n",
    "            num_correct.append(int((torch.flatten(tgt)==torch.flatten(pred_word)).sum()))\n",
    "            num_test += int(torch.flatten(pred_word).size(0))\n",
    "            \n",
    "            y_probability = np.append(y_probability, logits.cpu().detach().numpy())\n",
    "            y_pred = np.append(y_pred, pred_word.cpu().detach().numpy())\n",
    "            y_true = np.append(y_true, tgt.cpu().detach().numpy())\n",
    "            \n",
    "    accuracy = sum(num_correct) / num_test\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return losses / len(data_loader), accuracy,  y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 75/75 [00:00<00:00, 139.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.9419976234436036,\n",
       " 0.11638020833333333,\n",
       " array([3., 2., 1., ..., 6., 6., 3.]),\n",
       " array([   2.,    6.,    5., ...,    6., -100.,    3.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8)\n",
    "train_epoch(model, optimizer=optimizer, data_loader=train_loader, max_length=max_length)\n",
    "test_epoch_check(model, optimizer=optimizer, data_loader=validation_loader, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slack_alarm(message):\n",
    "    \"\"\"\n",
    "    message : string\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from slack import WebClient\n",
    "    from slack.errors import SlackApiError\n",
    "\n",
    "    SLACK_API_TOKEN = 'xoxb-3456243383942-3465240022692-nQxw8PlFwhcywqhYlzO3jqmX'\n",
    "    client = WebClient(token=SLACK_API_TOKEN)\n",
    "\n",
    "    try:\n",
    "        response = client.chat_postMessage(channel='#deep-learning',text=message)\n",
    "        assert response[\"message\"][\"text\"] == message\n",
    "\n",
    "        #filepath=\"./tmp.txt\"\n",
    "        #response = client.files_upload(channels='#random', file=filepath)\n",
    "        #assert response[\"file\"]  # the uploaded file\n",
    "    except SlackApiError as e:\n",
    "        # You will get a SlackApiError if \"ok\" is False\n",
    "        assert e.response[\"ok\"] is False\n",
    "        assert e.response[\"error\"]  # str like 'invalid_auth', 'channel_not_found'\n",
    "        print(f\"Got an error: {e.response['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_sample(model, optimizer, max_length, train_loader, validation_loader, test_loader, device, total_num_epoch, running_num_epoch, tf_board_directory, model_save_directory, best_model_save_directory=None, slack_message=False):\n",
    "    '''\n",
    "    Parameters:\n",
    "        train_loader\n",
    "        validation_loader\n",
    "        test_loader\n",
    "        total_num_epoch : the total number of epoch that have run\n",
    "        running_num_epoch : the number of epoch that run in this time\n",
    "        tf_board_directory\n",
    "        model_save_directory : save directory to save the final model\n",
    "        best_model_save_directory : [optional] save directory to save the best model (best validation accuracy)\n",
    "        slack_message : [boolian] slack message notification (current epoch)\n",
    "    '''\n",
    "    #################################################################################\n",
    "    # load modules and set parameters\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter(tf_board_directory)\n",
    "        ## logdir=./python/run/GAT_Net/run_02\n",
    "\n",
    "    if (total_num_epoch < 0 or running_num_epoch <= 0):\n",
    "        import sys\n",
    "        sys.exit(\"Check the number of epoch. It is incorrect\")\n",
    "\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=3e-6, weight_decay=0.95)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.7, patience=50, min_lr=1e-8)\n",
    "\n",
    "    #################################################################################\n",
    "    #running code\n",
    "    import time\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    total_time_start = time.time() # to measure time\n",
    "    best_validation_accuracy = None\n",
    "    for epoch in tqdm(range(1, running_num_epoch+1)):\n",
    "        epoch_time_start = time.time() # to measure time\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "        loss, train_accuracy = train_epoch(model, optimizer, train_loader, max_length=max_length)\n",
    "        _, validation_accuracy, _, _ = test_epoch(model, optimizer, validation_loader, max_length=max_length)\n",
    "        #scheduler.step(validation_accuracy)\n",
    "\n",
    "        # to save the metrics and model\n",
    "        if best_validation_accuracy is None or validation_accuracy >= best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "            if not(best_model_save_directory is None):            \n",
    "                torch.save({\n",
    "                'epoch': total_num_epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, best_model_save_directory)\n",
    "        _, test_accuracy, _, _ = test_epoch(model, optimizer, test_loader, max_length=max_length)\n",
    "        total_num_epoch = total_num_epoch + 1\n",
    "        epoch_time_end = time.time() # to measure time    \n",
    "        writer.add_scalar('loss in train', loss, total_num_epoch) #tensorboard\n",
    "        writer.add_scalar('train accuracy', train_accuracy, total_num_epoch) #tensorboard\n",
    "        writer.add_scalar('validation accuracy', validation_accuracy, total_num_epoch) #tensorboard    \n",
    "        writer.add_scalar('test accuracy', test_accuracy, total_num_epoch) #tensorboard\n",
    "        writer.add_scalar('learning rate', lr, total_num_epoch) #tensorboard\n",
    "        # print(f'ToTal Epoch: {total_num_epoch:03d}, LR: {lr:7f}, Loss: {loss:.7f}, '\n",
    "        #       f'Val MAE: {validation_error:.7f}, Test MAE: {test_error:.7f}, Time: {epoch_time_end - epoch_time_start}')\n",
    "\n",
    "        # to send message\n",
    "        if slack_message:\n",
    "            slack_alarm('[Life3 server JupyterNotebook] : ' + str(epoch) + ' / ' + str(running_num_epoch) + '\\ntrain accuracy: ' + str(train_accuracy) + '\\nvalidation_accuracy: ' + str(validation_accuracy) + '\\ntest_accuracy: ' + str(test_accuracy))\n",
    "            \n",
    "    total_time_finish = time.time() # to measure time\n",
    "    print(f'Done. Total running Time: {total_time_finish - total_time_start}')\n",
    "    writer.close() #tensorboard : if close() is not declared, the writer does not save any valeus.\n",
    "\n",
    "    # model save\n",
    "    torch.save({\n",
    "            'epoch': total_num_epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, model_save_directory)\n",
    "    print('total number of epoches : ', total_num_epoch)\n",
    "    print(\"-------------------------done------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [01:49<00:00, 54.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Total running Time: 109.69192624092102\n",
      "total number of epoches :  2\n",
      "-------------------------done------------------------------\n"
     ]
    }
   ],
   "source": [
    "save_directory = 'run_03'\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0015334791245047435)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.8, patience=10, min_lr=1e-4)\n",
    "\n",
    "train_all_sample(model=model,\n",
    "                optimizer=optimizer,\n",
    "                max_length=max_length,\n",
    "                train_loader=train_loader, \n",
    "                validation_loader=validation_loader, \n",
    "                test_loader=test_loader, \n",
    "                device='cuda', \n",
    "                total_num_epoch=0, \n",
    "                running_num_epoch=2, \n",
    "                tf_board_directory = 'tfboard/'+save_directory, \n",
    "                model_save_directory='model/'+save_directory, \n",
    "                best_model_save_directory='model/'+save_directory+'_best',\n",
    "                slack_message = True)\n",
    "del save_directory\n",
    "slack_alarm('The program execution on JupyterNotebook is done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "pretrained_model = BertModel.from_pretrained('skt/kobert-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class KoBERTNER(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768, #768\n",
    "                 num_labels=29,\n",
    "                 max_length=512, \n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(KoBERTNER, self).__init__()\n",
    "        self.bert = bert # Load model body\n",
    "        self.dr_rate = dr_rate\n",
    "        self.max_length = max_length\n",
    "        # Set up token classification head\n",
    "        self.num_labels = num_labels # num_tags\n",
    "        self.classifier = nn.Linear(hidden_size, self.max_length*self.num_labels)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "            \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask) #[batch_size, hidden_dim]\n",
    "            # ouitput[0] : the attention weights\n",
    "            # output[1] : the output from the model\n",
    "        # Apply classifier to encoder representation\n",
    "        output = self.dropout(output[1])\n",
    "        output = self.classifier(output) #[batch_size, max_length*num_label]\n",
    "        output = output.view([-1, self.num_labels, self.max_length]) # [batch_size, num_label, max_length]\n",
    "        return output\n",
    "#     def forward(self, token_ids, valid_length, segment_ids):\n",
    "#         attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "#         # Use model body to get encoder representations\n",
    "#         _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "#         # Apply classifier to encoder representation\n",
    "#         sequence_output = self.dropout(pooler)\n",
    "#         logits = self.classifier(sequence_output)\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "model = KoBERTNER(pretrained_model, dr_rate=0.3).to(DEVICE)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0015334791245047435)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.8, patience=5, min_lr=0.00001)\n",
    "#optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "PATH = 'model/run_01_best'\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_visualization(model, optimizer, data_loader, max_length=max_length, DEVICE='cuda'):\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        losses = 0\n",
    "        num_correct = []\n",
    "        num_test = 0\n",
    "        y_probability = np.array([])\n",
    "        y_pred = np.array([])\n",
    "        y_true = np.array([])\n",
    "        for src, tgt in data_loader:\n",
    "            src = src.type(torch.LongTensor).to(DEVICE)\n",
    "            tgt = tgt.type(torch.LongTensor).to(DEVICE)\n",
    "            logits = model(input_ids= src, attention_mask= torch.tensor([[1]*max_length]*batch_size).to(DEVICE))\n",
    "                #torch.Size([batch_size, , num_tag, src_seq_length])\n",
    "            \n",
    "            loss = loss_fn(logits, tgt)\n",
    "            losses += loss.item()\n",
    "            \n",
    "            # accuracy\n",
    "            _, pred_word = torch.max(logits, dim=1)\n",
    "            num_correct.append(int((torch.flatten(tgt)==torch.flatten(pred_word)).sum()))\n",
    "            num_test += int(torch.flatten(pred_word).size(0))\n",
    "            \n",
    "            y_probability = np.append(y_probability, logits.cpu().detach().numpy())\n",
    "            y_pred = np.append(y_pred, pred_word.cpu().detach().numpy())\n",
    "            y_true = np.append(y_true, tgt.cpu().detach().numpy())\n",
    "            \n",
    "    accuracy = sum(num_correct) / num_test\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return losses / len(data_loader), accuracy,  y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, pred, true = test_epoch(model=model, optimizer=optimizer, data_loader= test_loader, max_length=max_length, DEVICE='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7274990410640322"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 2 3 4] [true f t f ] -> [1 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import compress\n",
    "list_a = [1, 2, 4, 6]\n",
    "fil = [True, False, True, False]\n",
    "list(compress(list_a, fil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "true_vis = list(compress(true, [(x==5 or x==6) for x in true]))\n",
    "pred_vis = list(compress(pred, [(x==5 or x==6) for x in true]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55970</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55971</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55972</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55973</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55974</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction  label\n",
       "0             5.0    5.0\n",
       "1             5.0    5.0\n",
       "2             6.0    6.0\n",
       "3             5.0    5.0\n",
       "4             6.0    5.0\n",
       "...           ...    ...\n",
       "55970         5.0    5.0\n",
       "55971         5.0    6.0\n",
       "55972         5.0    6.0\n",
       "55973         6.0    5.0\n",
       "55974         5.0    5.0\n",
       "\n",
       "[55975 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_result = pd.DataFrame({'prediction' : pred_vis, 'label' : true_vis})\n",
    "ner_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [x==y for (x,y) in zip(true_vis, pred_vis)]\n",
    "acc = sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5042072353729343"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., 6., 5., 5., 5., 6., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       6., 6., 5., 6., 6., 5., 5., 6., 6., 6., 5., 6., 5., 5., 6., 6., 5.,\n",
       "       5., 5., 5., 5., 6., 5., 5., 5., 6., 5., 6., 5., 5., 3., 2., 5., 5.,\n",
       "       5., 6., 5., 5., 6., 5., 6., 6., 6., 6., 5., 5., 6., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 6., 6., 5., 5., 5., 5., 5., 6., 5., 6., 6., 5.,\n",
       "       6., 5., 6., 5., 5., 6., 6., 5., 6., 6., 5., 5., 6., 5., 5., 6., 5.,\n",
       "       6., 6., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5., 6., 5., 5., 6., 6.,\n",
       "       5., 5., 6., 5., 5., 6., 5., 6., 6., 5., 6., 6., 6., 6., 5., 6., 5.,\n",
       "       5., 6., 5., 6., 5., 5., 6., 5., 6., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       6., 6., 5., 5., 6., 6., 5., 5., 5., 6., 5., 6., 5., 5., 5., 5., 6.,\n",
       "       5., 6., 5., 5., 6., 5., 5., 6., 5., 5., 5., 5., 5., 6., 5., 5., 5.,\n",
       "       6., 6., 6., 5., 5., 6., 5., 5., 5., 5., 5., 5., 5., 6., 5., 6., 6.,\n",
       "       6., 5., 5., 5., 5., 5., 5., 6., 6., 6., 5., 6., 5., 5., 6., 5., 5.,\n",
       "       5., 6., 5., 5., 5., 6., 5., 6., 6., 5., 5., 5., 5., 6., 6., 6., 5.,\n",
       "       6., 6., 5., 6., 5., 6., 5., 6., 6., 5., 5., 6., 6., 6., 6., 5., 5.,\n",
       "       5., 5., 6., 6., 5., 5., 5., 6., 6., 5., 6., 6., 6., 5., 6., 5., 5.,\n",
       "       6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5., 5., 5., 5., 6., 5.,\n",
       "       6., 5., 6., 5., 5., 6., 6., 6., 5., 5., 6., 6., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6., 5., 5., 5., 5., 6., 5.,\n",
       "       5., 5., 5., 6., 5., 6., 5., 5., 6., 5., 6., 6., 5., 6., 6., 5., 6.,\n",
       "       5., 5., 6., 6., 5., 6., 6., 6., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       6., 6., 6., 5., 6., 5., 6., 5., 6., 6., 5., 6., 5., 6., 6., 5., 6.,\n",
       "       6., 5., 6., 5., 5., 6., 6., 5., 5., 5., 5., 6., 5., 6., 6., 5., 6.,\n",
       "       6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5., 5., 5., 5., 5., 6.,\n",
       "       5., 6., 5., 5., 5., 6., 5., 5., 5., 6., 6., 5., 6., 5., 6., 6., 5.,\n",
       "       5., 5., 6., 6., 6., 5., 5., 5., 6., 6., 5., 5., 6., 6., 5., 5., 5.,\n",
       "       5., 5., 5., 6., 6., 5., 6., 6., 6., 5., 6., 6., 6., 6., 5., 5., 6.,\n",
       "       5., 5., 5., 6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 6., 5., 5., 5., 5., 5., 6., 5., 5., 5., 6., 6., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 6., 6., 5., 5., 6., 5., 5., 5., 6., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 6., 5., 5., 5., 6., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 6., 6., 5., 6., 6., 5., 5., 6., 6., 6., 5., 6., 5., 5., 6.,\n",
       "       6., 5., 5., 5., 5., 5., 6., 5., 5., 5., 6., 5., 6., 5., 5., 3., 2.,\n",
       "       5., 5., 5., 6., 5., 5., 6., 5., 6., 6., 6., 6., 5., 5., 6., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 6., 6., 5., 5., 5., 5., 5., 6., 5., 6.,\n",
       "       6., 5., 6., 5., 6., 5., 5., 6., 6., 5., 6., 6., 5., 5., 6., 5., 5.,\n",
       "       6., 5., 6., 6., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5., 6., 5., 5.,\n",
       "       6., 6., 5., 5., 6., 5., 5., 6., 5., 6., 6., 5., 6., 6., 6., 6., 5.,\n",
       "       6., 5., 5., 6., 5., 6., 5., 5., 6., 5., 6., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 6., 6., 5., 5., 6., 6., 5., 5., 5., 6., 5., 6., 5., 5., 5.,\n",
       "       5., 6., 5., 6., 5., 5., 6., 5., 5., 6., 5., 5., 5., 5., 5., 6., 5.,\n",
       "       5., 5., 6., 6., 6., 5., 5., 6., 5., 5., 5., 5., 5., 5., 5., 6., 5.,\n",
       "       6., 6., 6., 5., 5., 5., 5., 5., 5., 6., 6., 6., 5., 6., 5., 5., 6.,\n",
       "       5., 5., 5., 6., 5., 5., 5., 6., 5., 6., 6., 5., 5., 5., 5., 6., 6.,\n",
       "       6., 5., 6., 6., 5., 6., 5., 6., 5., 6., 6., 5., 5., 6., 6., 6., 6.,\n",
       "       5., 5., 5., 5., 6., 6., 5., 5., 5., 6., 6., 5., 6., 6., 6., 5., 6.,\n",
       "       5., 5., 6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5., 5., 5., 5.,\n",
       "       6., 5., 6., 5., 6., 5., 5., 6., 6., 6., 5., 5., 6., 6., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6., 5., 5., 5., 5.,\n",
       "       6., 5., 5., 5., 5., 6., 5., 6., 5., 5., 6., 5., 6., 6., 5., 6., 6.,\n",
       "       5., 6., 5., 5., 6., 6., 5., 6., 6., 6., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 6., 6., 6., 5., 6., 5., 6., 5., 6., 6., 5., 6., 5., 6., 6.,\n",
       "       5., 6., 6., 5., 6., 5., 5., 6., 6., 5., 5., 5., 5., 6., 5., 6., 6.,\n",
       "       5., 6., 6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 6., 5., 6., 5., 5., 5., 6., 5., 5., 5., 6., 6., 5., 6., 5., 6.,\n",
       "       6., 5., 5., 5., 6., 6., 6., 5., 5., 5., 6., 6., 5., 5., 6., 6., 5.,\n",
       "       5., 5., 5., 5., 5., 6., 6., 5., 6., 6., 6., 5., 6., 6., 6., 6., 5.,\n",
       "       5., 6., 5., 5., 5., 6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 6., 5., 5., 5., 5., 5., 6., 5., 5., 5.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100., -100.,    6., -100., -100.,    6., -100., -100.,    6.,\n",
       "          6., -100.,    6., -100.,    5., -100.,    6., -100., -100.,\n",
       "       -100.,    6., -100.,    6., -100.,    3.,    2.,    5., -100.,\n",
       "          6.,    5., -100., -100.,    5., -100.,    6., -100.,    5.,\n",
       "       -100., -100., -100., -100.,    5., -100.,    6.,    5., -100.,\n",
       "       -100.,    5., -100., -100., -100.,    5., -100.,    6.,    6.,\n",
       "          5., -100., -100.,    6., -100.,    5., -100., -100.,    5.,\n",
       "          6., -100., -100.,    5., -100.,    5.,    6., -100.,    6.,\n",
       "       -100.,    6., -100.,    5., -100.,    5., -100.,    5., -100.,\n",
       "       -100., -100., -100., -100.,    5.,    5.,    5.,    6.,    5.,\n",
       "       -100.,    5., -100.,    6., -100.,    5.,    6., -100.,    5.,\n",
       "       -100.,    5.,    5.,    5.,    5., -100., -100., -100., -100.,\n",
       "          5., -100.,    6.,    6., -100., -100.,    5., -100.,    6.,\n",
       "       -100.,    6., -100., -100.,    5.,    6.,    5., -100.,    6.,\n",
       "          5.,    6., -100.,    5., -100.,    6., -100.,    6., -100.,\n",
       "       -100.,    6., -100.,    6., -100., -100., -100.,    6., -100.,\n",
       "       -100.,    5., -100., -100.,    6., -100.,    5., -100.,    6.,\n",
       "          6., -100.,    6., -100.,    5., -100.,    6., -100.,    6.,\n",
       "       -100.,    6.,    5.,    5.,    6., -100.,    5., -100.,    5.,\n",
       "       -100., -100.,    5., -100.,    5., -100., -100.,    5.,    5.,\n",
       "          5., -100., -100., -100.,    5., -100.,    5., -100.,    5.,\n",
       "       -100.,    6., -100.,    6.,    5., -100.,    5., -100., -100.,\n",
       "          6., -100., -100.,    6., -100.,    5., -100., -100.,    6.,\n",
       "       -100., -100.,    6., -100.,    6., -100.,    5.,    6., -100.,\n",
       "       -100., -100.,    6., -100., -100.,    6., -100., -100.,    6.,\n",
       "          5., -100.,    5., -100., -100.,    6.,    6., -100., -100.,\n",
       "          5., -100.,    6.,    6., -100.,    5.,    6., -100.,    6.,\n",
       "       -100.,    6., -100.,    6., -100.,    5., -100., -100.,    6.,\n",
       "       -100., -100.,    5.,    5.,    6.,    5., -100.,    6., -100.,\n",
       "       -100.,    5., -100.,    5., -100.,    5., -100., -100.,    5.,\n",
       "          5., -100.,    5., -100.,    5.,    6., -100., -100.,    5.,\n",
       "       -100., -100., -100.,    6.,    6., -100., -100.,    6., -100.,\n",
       "          5., -100., -100., -100.,    6., -100.,    5., -100.,    6.,\n",
       "       -100.,    5., -100.,    6., -100.,    6., -100., -100.,    5.,\n",
       "       -100.,    6.,    5.,    5.,    6.,    6., -100., -100.,    6.,\n",
       "       -100.,    6.,    6., -100., -100.,    5., -100.,    6.,    6.,\n",
       "       -100.,    5.,    6., -100., -100.,    5.,    5.,    6., -100.,\n",
       "       -100., -100.,    5.,    5., -100., -100., -100., -100.,    6.,\n",
       "       -100.,    6.,    6., -100.,    5., -100.,    5., -100.,    6.,\n",
       "          5.,    5., -100.,    6., -100.,    5.,    6., -100., -100.,\n",
       "       -100., -100.,    6., -100.,    5.,    5., -100.,    6., -100.,\n",
       "          5., -100., -100., -100.,    6., -100., -100.,    6., -100.,\n",
       "          5., -100.,    5.,    5., -100.,    5., -100., -100., -100.,\n",
       "          6.,    6., -100.,    5., -100.,    6.,    5.,    6.,    5.,\n",
       "          6.,    6., -100.,    5., -100.,    5., -100., -100.,    6.,\n",
       "          5.,    5., -100.,    6., -100., -100.,    5.,    5., -100.,\n",
       "          6., -100.,    6.,    6.,    5., -100., -100.,    5., -100.,\n",
       "          6., -100., -100.,    6.,    5.,    5.,    5., -100.,    6.,\n",
       "       -100., -100.,    5., -100.,    6., -100., -100., -100.,    6.,\n",
       "          6.,    5., -100.,    5., -100., -100., -100.,    6., -100.,\n",
       "       -100.,    5.,    5.,    6., -100., -100.,    5.,    6.,    5.,\n",
       "       -100., -100.,    5.,    6., -100.,    6., -100.,    6., -100.,\n",
       "       -100.,    6.,    6., -100., -100., -100.,    5., -100.,    6.,\n",
       "       -100.,    6., -100.,    5.,    5., -100., -100.,    6., -100.,\n",
       "          6., -100.,    6., -100., -100.,    5.,    5.,    5.,    5.,\n",
       "          5., -100., -100., -100., -100.,    6.,    5., -100., -100.,\n",
       "          6., -100.,    5.,    5., -100., -100., -100.,    5., -100.,\n",
       "       -100.,    5.,    6., -100., -100.,    6.,    6.,    5.,    5.,\n",
       "       -100.,    6.,    6., -100.,    6., -100.,    6.,    6.,    6.,\n",
       "       -100., -100.,    6., -100.,    3.,    2., -100., -100., -100.,\n",
       "          6., -100.,    6.,    5., -100.,    5.,    5.,    5.,    5.,\n",
       "       -100.,    5.,    5., -100.,    5., -100.,    5., -100.,    5.,\n",
       "       -100., -100., -100., -100.,    5., -100., -100.,    6., -100.,\n",
       "          6., -100., -100., -100.,    6., -100.,    6.,    5., -100.,\n",
       "          6., -100.,    6., -100.,    5., -100.,    6., -100.,    5.,\n",
       "       -100.,    5., -100.,    5.,    5.,    5., -100., -100., -100.,\n",
       "          6., -100.,    5., -100.,    6., -100.,    6., -100., -100.,\n",
       "       -100.,    5., -100.,    5., -100.,    5., -100.,    6., -100.,\n",
       "          5.,    5., -100.,    5., -100., -100., -100.,    5., -100.,\n",
       "       -100., -100.,    5.,    6., -100.,    5.,    6., -100.,    5.,\n",
       "          5.,    5.,    5., -100.,    6., -100.,    5., -100., -100.,\n",
       "          5., -100., -100.,    5., -100.,    5., -100., -100., -100.,\n",
       "          5., -100.,    5., -100.,    6.,    6.,    5., -100., -100.,\n",
       "          6., -100., -100.,    6.,    6., -100.,    6., -100.,    5.,\n",
       "       -100., -100., -100.,    6.,    6., -100.,    5.,    6., -100.,\n",
       "          5., -100., -100.,    5., -100.,    6.,    6.,    5., -100.,\n",
       "          5., -100.,    5., -100.,    5.,    5., -100., -100.,    6.,\n",
       "          5., -100., -100.,    5., -100., -100.,    5.,    5., -100.,\n",
       "          5.,    6.,    6.,    5., -100., -100.,    5., -100., -100.,\n",
       "          5., -100.,    5., -100.,    5.,    6.,    6.,    5., -100.,\n",
       "       -100.,    6., -100., -100.,    6.,    6.,    6., -100.,    5.,\n",
       "          5., -100.,    6., -100., -100.,    5., -100., -100.,    5.,\n",
       "       -100.,    5., -100.,    6.,    6.,    5.,    5.,    6., -100.,\n",
       "          5., -100.,    6., -100.,    5.,    5.,    6.,    6., -100.,\n",
       "          5., -100.,    5.,    6., -100., -100., -100.,    6., -100.,\n",
       "          5., -100., -100., -100.,    5.,    5., -100., -100., -100.,\n",
       "       -100.,    6., -100.,    5., -100.,    5.,    5.,    6., -100.,\n",
       "          6., -100., -100.,    5., -100.,    6., -100., -100.,    6.,\n",
       "       -100., -100.,    6., -100., -100., -100.,    5.,    5., -100.,\n",
       "          6., -100., -100., -100.,    5., -100.,    6., -100.,    5.,\n",
       "       -100.,    6., -100., -100.,    5.,    6., -100., -100.,    5.,\n",
       "       -100., -100.,    6., -100., -100.,    5., -100., -100.,    5.,\n",
       "       -100., -100., -100., -100.,    6.,    6., -100., -100.,    6.,\n",
       "          6., -100., -100., -100.,    5.,    6., -100., -100.,    5.,\n",
       "       -100., -100.,    6., -100., -100.,    5., -100.,    6.,    5.,\n",
       "       -100., -100.,    6.,    6., -100.,    5., -100.,    5., -100.,\n",
       "          5., -100.,    5., -100.,    5., -100.,    5., -100., -100.,\n",
       "       -100.,    5., -100., -100., -100., -100.,    6., -100.,    6.,\n",
       "       -100.,    6., -100., -100.,    6., -100.,    6., -100., -100.,\n",
       "          6., -100.,    5.,    6., -100., -100., -100.,    6.,    6.,\n",
       "       -100.,    6., -100., -100.,    5., -100.,    6.,    5., -100.,\n",
       "          6.,    5.,    5.,    6.,    6., -100., -100.,    5., -100.,\n",
       "       -100., -100., -100.,    5., -100., -100., -100., -100.,    6.,\n",
       "       -100.,    6., -100., -100.,    6., -100.,    6., -100., -100.,\n",
       "          6., -100., -100.,    6., -100., -100.,    6., -100.,    5.,\n",
       "          6., -100., -100.,    6., -100., -100., -100.,    6., -100.,\n",
       "       -100.,    5.,    5., -100.,    6., -100., -100.,    5., -100.,\n",
       "          5.,    6., -100.,    6., -100., -100., -100., -100.,    6.,\n",
       "       -100., -100.,    6., -100., -100.,    6., -100., -100., -100.,\n",
       "          6., -100., -100.,    6., -100., -100., -100., -100., -100.,\n",
       "          5., -100.,    5., -100., -100., -100., -100.,    6., -100.,\n",
       "          6.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "tokenizer.encode(\"한국어 모델을 공유합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE-dropout을 이용하면 서비스에 적합한 띄어쓰기에 강건한 모델로 튜닝 할 수 있습니다. 학습시 아래와 유사한 토크나이저 설정으로 학습을 진행할 수 있습니다. 자세한 옵션 설명은 이곳을 참고하세요  \n",
    "https://github.com/SKTBrain/KoBERT/tree/master/kobert_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "import gluonnlp as nlp\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "pretrained_model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "text = \"한국어 모델을 공유합니다.\"\n",
    "inputs = tokenizer.batch_encode_plus([text])\n",
    "out = pretrained_model(input_ids = torch.tensor(inputs['input_ids']),\n",
    "              attention_mask = torch.tensor(inputs['attention_mask']))\n",
    "out.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1554, -0.0150,  0.3673,  ..., -0.0094,  0.1067,  0.0844],\n",
       "         [ 0.1229, -0.3236, -0.0669,  ..., -0.4487, -0.1753, -0.2302],\n",
       "         [ 0.1008, -0.3885, -0.1219,  ..., -0.2129, -0.0330, -0.1708],\n",
       "         ...,\n",
       "         [-0.0700,  0.1174, -0.1385,  ..., -0.0272,  0.5141, -0.0093],\n",
       "         [-0.0605, -0.2776,  0.4285,  ..., -0.2879,  0.5493,  0.0797],\n",
       "         [-0.1537, -0.1819, -0.1994,  ..., -0.2862,  0.0133,  0.0783]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.5197e-02,  1.2525e-02, -2.0906e-02, -4.9571e-02, -9.7731e-01,\n",
       "          9.9156e-01, -6.7530e-01,  5.5347e-02,  2.3231e-02,  4.5099e-03,\n",
       "         -5.1811e-01, -3.6802e-02, -4.0091e-02, -7.1836e-02, -2.3317e-02,\n",
       "          8.3534e-01, -9.9642e-01,  5.2746e-02,  2.5372e-03, -8.5501e-02,\n",
       "          1.1586e-01, -4.6591e-02, -2.1023e-02,  5.6610e-01,  3.4027e-02,\n",
       "          7.5981e-01, -9.3067e-01, -6.7136e-02, -9.6185e-01, -1.7121e-01,\n",
       "          9.5807e-01,  5.7800e-01, -1.9472e-02, -4.1815e-02, -9.3780e-01,\n",
       "          4.9916e-02, -5.7409e-03, -2.2729e-02, -9.9425e-01, -6.9237e-02,\n",
       "          6.8458e-04,  3.4909e-02, -6.2844e-03,  9.9442e-01, -9.9899e-01,\n",
       "          4.0310e-02, -5.3533e-01, -2.2571e-02, -9.9929e-01,  9.8811e-01,\n",
       "         -1.2751e-01, -9.9998e-01, -9.9651e-01,  5.4741e-03, -3.5815e-02,\n",
       "         -8.2744e-01,  3.8543e-02,  8.0260e-01,  2.5858e-02, -3.3279e-02,\n",
       "          3.3251e-02, -1.3364e-02,  9.6320e-01, -9.9580e-01,  2.3712e-02,\n",
       "         -9.8592e-03, -2.1819e-02,  5.7131e-02,  1.9689e-02, -3.2284e-02,\n",
       "          9.7799e-01, -9.0611e-02,  1.7279e-01, -3.2946e-02, -5.7409e-01,\n",
       "          5.7607e-05,  3.2987e-02, -2.1082e-02,  1.1405e-01, -7.1177e-02,\n",
       "          2.7412e-02, -9.9241e-01, -6.7661e-01,  2.8413e-01,  2.0271e-03,\n",
       "         -3.9799e-02,  1.1175e-01, -6.5503e-02,  9.9622e-01, -8.3377e-01,\n",
       "          4.3311e-02, -2.6061e-02, -3.0420e-02,  4.8004e-02, -9.8523e-01,\n",
       "         -4.1779e-03,  1.7801e-02, -5.3233e-02,  1.1994e-02,  8.4690e-01,\n",
       "          3.1512e-03, -9.9730e-03,  1.0782e-02, -7.0631e-03, -9.6009e-01,\n",
       "         -5.2606e-02, -3.7218e-03, -3.6499e-02, -1.3428e-03,  9.6022e-03,\n",
       "          1.2540e-02, -4.1232e-02,  9.6691e-01,  1.4780e-02,  2.9358e-01,\n",
       "         -1.1180e-02, -2.6618e-03, -4.7588e-03,  3.1942e-02,  3.5106e-02,\n",
       "          8.3404e-02, -6.5394e-02, -9.9862e-01,  9.5117e-01, -9.9999e-01,\n",
       "          1.0239e-03, -8.7128e-01, -7.1489e-02, -3.0124e-02, -9.1398e-02,\n",
       "         -1.1825e-02,  2.4025e-02,  1.5446e-02,  8.2456e-02, -1.4861e-02,\n",
       "         -5.0143e-02, -8.9484e-01,  5.6974e-03,  4.4965e-02, -5.3344e-02,\n",
       "         -3.0325e-03,  6.7165e-02,  1.0825e-01,  8.2402e-01, -1.8424e-02,\n",
       "          6.7906e-02,  3.0822e-02,  2.8488e-02,  3.5309e-02,  1.5438e-02,\n",
       "         -9.8715e-01, -6.0994e-02, -9.1701e-01, -3.8465e-02,  1.2546e-02,\n",
       "          5.3762e-02,  3.0931e-02, -7.0557e-03,  1.4816e-03, -9.4359e-01,\n",
       "          1.0758e-02,  5.6370e-02,  3.6725e-02,  9.9708e-01,  3.1692e-02,\n",
       "          1.1596e-03, -1.4543e-02,  4.3772e-01, -2.6825e-02, -4.5654e-02,\n",
       "         -5.8780e-02, -5.8295e-02, -9.9117e-01, -6.8371e-01,  7.8358e-02,\n",
       "          9.9997e-01,  2.8381e-02, -9.5989e-01, -2.5404e-03, -3.2165e-02,\n",
       "          9.8768e-02,  9.9097e-01,  8.6352e-02, -9.9999e-01,  7.0321e-03,\n",
       "         -1.0353e-02,  6.1644e-02, -1.5536e-02,  5.6378e-02,  4.5823e-01,\n",
       "         -3.2974e-02, -9.2151e-03, -8.3104e-01, -1.9364e-02,  7.2397e-03,\n",
       "         -1.2476e-02,  2.1621e-01, -1.8091e-03, -3.4680e-02,  1.2223e-02,\n",
       "         -2.0087e-02,  6.7524e-01,  2.7462e-02, -1.7319e-02,  9.6150e-01,\n",
       "          4.1261e-03, -8.5152e-02,  3.8312e-02, -5.9093e-01,  9.5981e-01,\n",
       "          7.2528e-03,  3.1033e-02,  9.5110e-01,  9.1042e-01,  1.1993e-01,\n",
       "          2.7888e-03, -1.5895e-02,  9.7395e-01,  9.4464e-01, -9.9836e-01,\n",
       "         -9.5188e-01,  1.6848e-02,  4.1660e-03,  4.0427e-02, -4.4811e-03,\n",
       "         -3.1519e-02,  9.8529e-01, -9.9806e-01, -2.1533e-02, -7.7940e-02,\n",
       "         -9.9560e-01, -2.1869e-04,  5.3599e-03, -2.5698e-01,  2.7291e-01,\n",
       "         -2.3914e-01,  5.3425e-01,  3.9196e-03,  3.2112e-03, -1.2114e-02,\n",
       "          9.3507e-01, -2.4086e-02,  9.3231e-01, -3.6020e-02,  7.5740e-01,\n",
       "          3.5909e-02, -2.5440e-02,  9.9753e-01,  1.2859e-01,  9.9417e-01,\n",
       "         -1.8082e-02, -3.7022e-02,  1.0731e-02, -9.5280e-03, -6.0838e-02,\n",
       "         -7.9809e-02,  9.9791e-01, -1.8525e-03,  9.9517e-01, -9.5933e-01,\n",
       "          5.3300e-02,  5.2023e-02,  6.4621e-03, -1.2404e-02,  2.6209e-01,\n",
       "          4.0104e-02, -2.9279e-03, -5.7839e-01, -9.6004e-01,  2.9432e-02,\n",
       "          5.6997e-02, -5.3312e-02,  4.8073e-03,  1.6104e-01,  8.4931e-01,\n",
       "         -9.4791e-01,  2.0395e-02, -9.2238e-03, -1.9253e-03,  3.9376e-02,\n",
       "          1.7074e-02,  4.0027e-01, -9.8209e-01,  3.5404e-02,  2.1782e-03,\n",
       "         -7.7997e-03, -1.7152e-02, -9.3239e-02,  2.0302e-02,  2.3005e-02,\n",
       "          9.8101e-01, -3.3570e-02,  7.5093e-01, -3.5337e-02,  2.1599e-02,\n",
       "         -5.6106e-02, -6.3388e-01,  9.9726e-01,  1.7765e-01,  3.1342e-02,\n",
       "         -5.6624e-02,  9.2133e-02, -4.1115e-02, -4.9083e-02,  9.9997e-01,\n",
       "          8.4378e-02, -6.6566e-01,  1.6984e-02,  2.1651e-02, -7.0314e-02,\n",
       "          6.4434e-02,  7.7849e-02,  5.7229e-02,  9.6833e-01,  9.9999e-01,\n",
       "         -3.0596e-02, -2.1304e-03, -3.0537e-02, -3.0713e-02,  6.3320e-02,\n",
       "         -5.1865e-02,  1.6238e-04,  3.4152e-02, -2.7721e-02, -5.6890e-02,\n",
       "         -9.9176e-02, -9.9096e-01,  2.8188e-02, -2.2624e-03, -1.5027e-02,\n",
       "         -4.5539e-02, -2.5171e-02, -9.5657e-01, -1.4087e-01, -9.6047e-01,\n",
       "         -2.2658e-02,  1.6845e-02, -9.2824e-02, -6.2046e-02,  9.5685e-01,\n",
       "          3.8434e-02,  2.0035e-02,  8.2179e-01, -8.4108e-03, -9.8684e-01,\n",
       "         -9.9978e-01,  8.8909e-03,  8.5371e-01, -5.6934e-02,  5.8383e-02,\n",
       "         -9.9471e-02, -8.8987e-02, -2.9000e-01,  4.4525e-02, -4.8241e-02,\n",
       "         -5.0009e-03, -7.3095e-01,  9.9998e-01,  9.2479e-03,  1.7111e-02,\n",
       "          1.9901e-02,  5.9194e-02, -5.7849e-01, -9.9301e-01,  2.2823e-02,\n",
       "         -1.4389e-02, -9.9871e-01, -5.9324e-04,  3.1265e-02,  2.1787e-03,\n",
       "         -9.3780e-01,  5.1154e-03, -5.8728e-02, -4.1728e-02,  1.2126e-01,\n",
       "          4.8315e-02, -9.2558e-01,  4.7209e-01, -1.3779e-02, -6.0363e-03,\n",
       "         -9.9998e-01,  5.7254e-03,  9.7654e-01, -5.1508e-02,  1.5155e-02,\n",
       "          4.1717e-02, -2.8035e-02, -9.1638e-03,  3.5194e-03, -6.1745e-02,\n",
       "         -9.5536e-01,  9.9996e-01, -3.6490e-01, -2.3475e-01,  7.5842e-02,\n",
       "         -1.7307e-01,  5.8301e-02, -9.4846e-03,  1.3548e-02,  1.9693e-02,\n",
       "         -9.4166e-03, -8.7349e-02,  1.1062e-01,  9.4669e-01, -7.8666e-01,\n",
       "          9.8472e-01,  6.9207e-02, -6.6394e-02, -4.1203e-01, -2.8216e-02,\n",
       "          1.8331e-02, -9.9501e-01, -9.6914e-01, -3.6959e-02, -2.0501e-02,\n",
       "         -5.5200e-01, -9.6724e-03, -3.2003e-02, -5.2948e-02, -3.2587e-02,\n",
       "         -3.5871e-02, -5.7683e-01, -1.7644e-03, -9.2759e-01,  8.5869e-01,\n",
       "         -3.4395e-02,  2.0066e-02, -5.8168e-01,  8.4513e-02, -6.3545e-02,\n",
       "         -4.9388e-01, -2.0328e-02, -5.5759e-01, -6.8314e-01, -3.4532e-01,\n",
       "         -5.0017e-02,  9.3841e-01, -2.8326e-01,  8.4987e-01,  9.3719e-01,\n",
       "          6.3603e-01,  1.9852e-03, -3.3372e-02,  9.9999e-01, -7.0330e-01,\n",
       "          4.8064e-02,  5.7000e-02,  6.3821e-01,  8.9572e-01, -1.8793e-02,\n",
       "         -9.5766e-01,  7.3249e-03, -9.7303e-01,  5.7000e-02, -4.8620e-02,\n",
       "          4.8303e-01,  3.9378e-02, -3.8751e-01,  1.3293e-03,  8.2993e-01,\n",
       "          2.3834e-02, -4.2979e-03, -4.3612e-02,  2.3217e-02, -1.9303e-02,\n",
       "          9.6390e-01,  2.4040e-02, -9.4583e-01, -9.4279e-02, -9.8666e-01,\n",
       "          2.4492e-02,  6.3368e-02,  7.4933e-03,  5.4627e-01, -1.5069e-03,\n",
       "         -4.0153e-01, -4.0157e-03, -4.0067e-02,  8.2598e-01,  9.4181e-02,\n",
       "         -9.9998e-01, -9.8626e-01, -9.3065e-01,  3.3449e-03,  2.6259e-01,\n",
       "         -9.8344e-01,  8.9739e-02,  7.5558e-02, -1.1075e-01, -9.9954e-01,\n",
       "         -5.7097e-02,  5.7236e-02, -5.3608e-02,  1.0742e-01, -9.3713e-01,\n",
       "         -7.5514e-03,  4.3232e-01, -2.4342e-03,  3.1717e-03, -1.4683e-01,\n",
       "         -9.9099e-01,  1.3144e-02, -3.1915e-02, -5.2123e-01, -2.4655e-02,\n",
       "          4.2343e-01,  2.3707e-01, -8.4742e-01,  9.9224e-01, -4.3127e-02,\n",
       "         -7.2845e-02, -4.3132e-01,  9.7068e-02,  7.9617e-03, -7.9714e-01,\n",
       "          9.2454e-01,  6.5169e-02, -1.9123e-02, -5.2972e-02, -9.3342e-02,\n",
       "         -3.4624e-02,  8.1650e-02, -1.8784e-02, -8.0761e-01, -7.1122e-03,\n",
       "          8.5199e-01,  5.0713e-02,  3.3225e-04,  6.9106e-02,  4.2433e-02,\n",
       "         -9.8644e-01,  3.3138e-03, -9.9184e-01, -2.9564e-02,  8.9984e-01,\n",
       "          7.2060e-01, -7.9699e-02,  1.2134e-02,  1.0020e-03, -9.9989e-01,\n",
       "         -2.9646e-03, -1.0000e+00,  7.8761e-02,  6.1437e-01, -3.4938e-02,\n",
       "         -2.3349e-02,  2.1532e-02,  1.8100e-02, -8.7273e-01, -9.2702e-01,\n",
       "         -4.7151e-02, -9.9999e-01, -9.8995e-01, -8.0021e-01, -9.4308e-02,\n",
       "          2.3066e-01,  4.6256e-02,  5.7805e-01, -1.8897e-02, -3.0696e-02,\n",
       "         -5.0692e-01, -6.9982e-02,  4.6907e-02,  3.9684e-02, -9.4130e-01,\n",
       "         -4.4868e-02,  2.5180e-02, -2.5698e-02,  2.3237e-02, -5.0230e-01,\n",
       "          7.0391e-03, -4.7195e-02,  2.6988e-02, -9.9311e-01,  2.9732e-02,\n",
       "          1.0654e-02,  3.9880e-02,  2.5688e-01, -7.8164e-02,  3.3405e-03,\n",
       "          6.0766e-02, -9.6415e-01,  2.8376e-04, -3.7492e-02,  8.8840e-01,\n",
       "         -9.1815e-03, -3.4285e-03, -9.6691e-01, -3.5383e-02,  7.5131e-01,\n",
       "          6.9293e-01,  6.9224e-01,  9.9303e-01,  7.8836e-02,  6.4091e-01,\n",
       "         -7.7385e-03, -4.3151e-01,  8.0024e-02,  9.5829e-01, -2.8434e-02,\n",
       "          1.5489e-03,  2.0705e-02, -9.8741e-01,  5.4546e-02, -9.9990e-01,\n",
       "          5.8355e-02, -9.8138e-01, -9.8336e-01, -1.3431e-03,  2.0571e-02,\n",
       "         -8.8442e-01, -7.1332e-01,  2.6191e-02, -1.8135e-02,  5.9189e-03,\n",
       "          1.6197e-02,  7.1327e-03, -9.5013e-01, -1.3307e-02,  5.8956e-01,\n",
       "         -1.3087e-02, -1.3999e-02,  4.2700e-02, -6.2579e-02, -2.7303e-02,\n",
       "          9.4154e-03, -1.4349e-02,  9.6016e-01,  4.4394e-01, -9.5806e-01,\n",
       "          8.1432e-01, -9.9055e-03, -9.5997e-01, -4.9583e-02,  3.1852e-02,\n",
       "         -5.6344e-03,  9.7473e-01,  3.0388e-02,  1.0000e+00,  9.9039e-01,\n",
       "         -9.6436e-01,  6.2123e-01,  1.2588e-03,  6.3712e-01, -5.6715e-02,\n",
       "         -9.5321e-01, -5.4789e-02, -9.4971e-01, -4.0235e-02,  6.9230e-03,\n",
       "          4.2838e-02, -3.1996e-01, -9.9841e-01,  2.5414e-02, -2.3247e-02,\n",
       "         -1.0253e-01, -9.1436e-01, -2.9565e-02, -9.9994e-01,  2.1628e-02,\n",
       "          9.8026e-01,  9.2917e-01, -3.8465e-02, -1.7672e-02,  9.9858e-01,\n",
       "          9.0906e-01, -9.3093e-01,  5.4479e-03,  3.8040e-02,  1.1974e-02,\n",
       "         -9.8447e-01, -1.9743e-02, -3.3284e-01, -4.8355e-04,  7.2251e-02,\n",
       "          1.2176e-02,  1.0974e-02,  5.4018e-01, -1.2867e-01, -5.4206e-02,\n",
       "          5.7445e-03,  9.0365e-01,  1.2500e-02, -9.6540e-02,  3.5239e-02,\n",
       "         -7.0963e-01,  5.5002e-02,  9.9998e-01,  8.4911e-01,  9.4085e-01,\n",
       "          9.9761e-01, -6.3109e-03, -4.0790e-02,  9.3981e-01,  6.3795e-01,\n",
       "          3.6250e-02, -7.2845e-02, -9.9647e-01, -1.8132e-02,  2.9783e-01,\n",
       "          9.6961e-01,  3.8222e-01, -9.9998e-01,  8.3316e-03,  9.8380e-01,\n",
       "          9.7967e-01, -6.5250e-01,  9.3331e-01, -9.8891e-01, -6.1939e-01,\n",
       "          3.6034e-02,  1.4953e-01, -7.4738e-01, -5.3545e-02,  4.3884e-02,\n",
       "          9.9999e-01,  1.5039e-01,  1.6797e-02,  2.6905e-02,  1.9737e-02,\n",
       "         -6.8264e-02, -4.8807e-02, -2.9707e-02,  9.4600e-01, -1.3704e-02,\n",
       "          3.7269e-03, -1.1898e-02, -9.9979e-01, -3.3232e-01, -2.0500e-01,\n",
       "         -1.3862e-02, -1.1782e-02, -9.9879e-01,  2.6497e-02, -4.6407e-02,\n",
       "         -7.0227e-04, -2.4122e-01,  2.3335e-03, -2.4632e-02,  3.5001e-01,\n",
       "         -9.9635e-03, -2.0773e-02, -1.5709e-02,  7.4071e-02,  5.5607e-02,\n",
       "          9.7022e-01, -6.7267e-01,  1.5011e-02,  1.9265e-01,  9.9499e-01,\n",
       "          1.2096e-02,  2.6780e-02, -5.0804e-01, -9.8375e-01, -9.6202e-01,\n",
       "          9.8026e-01,  3.7138e-02, -7.5123e-02, -3.8577e-02, -7.8318e-01,\n",
       "          3.1657e-01,  9.4517e-01, -7.7084e-01, -3.6669e-02, -9.9821e-01,\n",
       "          9.7941e-02, -5.3264e-03,  1.8042e-02]], grad_fn=<TanhBackward>), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
