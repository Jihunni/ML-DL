{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resource_tensorflow.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObwYXIv1RUF677m+BP3fq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jihunni/ML-DL/blob/main/Resource_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OP4eajzidO6"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5IMX5N-bS41",
        "outputId": "06b44770-4a60-4f4d-a4d1-1d2f0efc9f36"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if IS_COLAB or IS_KAGGLE:\n",
        "    !pip install -q -U tfx==0.21.2\n",
        "    print(\"You can safely ignore the package incompatibility errors.\")\n",
        "\n",
        "if IS_COLAB:\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    !pip install -q -U transformers\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"data\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 66.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 56.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 103 kB 71.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.2 MB 108 kB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 67.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 30.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 241 kB 21.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 38.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 36.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 151 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 218 kB 93.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 69.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 172 kB 69.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 232 kB 72.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 29 kB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 32 kB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.4 MB/s \n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/65/19/2060c8faa325fddc09aa67af98ffcb6813f39a0ad805679fa64815362b3a/grpc-google-iam-v1-0.12.3.tar.gz\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 111 kB 7.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 394.5 MB 31 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 26.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 45.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 13 kB/s \n",
            "\u001b[K     |█████████████████████████▏      | 310.4 MB 1.2 MB/s eta 0:01:10\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n",
            "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n",
            "    data = self.__fp.read(amt)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 465, in read\n",
            "    n = self.readinto(b)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 509, in readinto\n",
            "    n = self.fp.readinto(b)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 929, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 367, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 211, in _attempt_to_pin_criterion\n",
            "    for candidate in criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 129, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 54, in _iter_built_with_prepended\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 205, in _make_candidate_from_link\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 312, in __init__\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 151, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 234, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 318, in _prepare_distribution\n",
            "    self._ireq, parallel_builds=True\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 508, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 552, in _prepare_linked_requirement\n",
            "    self.download_dir, hashes\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 243, in unpack_url\n",
            "    hashes=hashes,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 102, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/network/download.py\", line 157, in __call__\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/progress_bars.py\", line 152, in iter\n",
            "    for x in it:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/network/utils.py\", line 86, in response_chunks\n",
            "    decode_content=False,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 541, in read\n",
            "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
            "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
            "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(104, 'Connection reset by peer')\", ConnectionResetError(104, 'Connection reset by peer'))\u001b[0m\n",
            "You can safely ignore the package incompatibility errors.\n",
            "\u001b[K     |████████████████████████████████| 679 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 55.2 MB/s \n",
            "\u001b[?25hNo GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n",
            "Go to Runtime > Change runtime and select a GPU hardware accelerator.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfcxuCiHbiXl"
      },
      "source": [
        "# Data type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnS5dEVpb2ag"
      },
      "source": [
        "## tensors and operations ( Hands-on p 379)\n",
        "- Numpy use 64-bit precision by default, while TensorFlow uses 32-bits.\n",
        "- tf.Tensor is immutable. (not modify them)\n",
        "- type conversions are not performed automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXjckCZnb28n"
      },
      "source": [
        "x = tf.range(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSIx8ZRXfppH"
      },
      "source": [
        "tensor = tf.constant([[1,2,3],[4,5,6,]])\n",
        "tensor.shape\n",
        "tensor.dtype\n",
        "\n",
        "#slicing\n",
        "tensor[:,1:]\n",
        "tensor[..., 1, tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHIRBAvJhSJI"
      },
      "source": [
        "#variable\n",
        "v = tf.Variable([1,2,3], [4,5,6])\n",
        "\n",
        "v.assign(2 * v)\n",
        "v[0, 1].assign(42)\n",
        "v[:,2].assign([0., 1.])\n",
        "v.scatter_nd_update(indices=[[0,0], [1,2]], updates=[100., 200.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMY4ZbyKgHdW"
      },
      "source": [
        "#operation\n",
        "##addition (these three are same; overriding)\n",
        "tensor + 10\n",
        "tf.add(tensor, 10)\n",
        "tf.math.add()\n",
        "\n",
        "tf.multiply()\n",
        "tf.square(tensor)\n",
        "tf.exp()\n",
        "tf.sqrt()\n",
        "tf.squeeze()\n",
        "tf.tile()\n",
        "tf.transpose()\n",
        "\n",
        "tf.reduce_mean()\n",
        "tf.reduce_sum()\n",
        "tf.reduce_max()\n",
        "tf.math.log()\n",
        "\n",
        "\n",
        "#matrix multiplication\n",
        "tensor @ tf.transpose(tensor) \n",
        "tf.matmul(tensor, tf.transpose(tensor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7uTD_I8bnrI"
      },
      "source": [
        "## Data API: dataset (Hand-on p414)\n",
        "Dataset is a sequence of data items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-0f6KMUbhYm"
      },
      "source": [
        "#create a dataset\n",
        "x = tf.range(10)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f16Ro5AXb71p"
      },
      "source": [
        "# iteration\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaC2-ID3b_pe"
      },
      "source": [
        "dataset_2 = dataset.repeat(3).batch(7)\n",
        "dataset_3 = dataset.repeat(3).batch(7, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW3RmbqLcRhG"
      },
      "source": [
        "#transform the items by calling the map()\n",
        "dataset_4 = dataset.map(lambda x : x * 2)\n",
        "\n",
        "#transform the dataset as a whole by calling apply()\n",
        "dataset_5 = dataset.apply(tf.data.experimental.unbatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX_V9LbSclzR"
      },
      "source": [
        "#filter\n",
        "dataset_6 = dataset.filter(lambda x : x <10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgNb1ij0eTbs"
      },
      "source": [
        "# shuffle\n",
        "dataset_7 = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
        "  ## enough buffer is required for proper shuffling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGLNQTf3dwmB"
      },
      "source": [
        "#### preprocessing (p419)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXQpPIzleLZb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjxQtEUcjY6P"
      },
      "source": [
        "### Prefetching (p421)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsuOUhSIuqXL"
      },
      "source": [
        "dataset = dataset.prefatch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIvYdJjGvfsp"
      },
      "source": [
        "### chopping the sequential Dataset into multiple windows (p528)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUd0xurCvoEj"
      },
      "source": [
        "#create a window\n",
        "n_steps = 100\n",
        "shift = 1 # target = input shifted 1 character ahead\n",
        "window_length = n_steps + shift\n",
        "dataset = dataset.window(window_length, shift, drop_reminder = True)\n",
        "\n",
        "#convert a nested dataset into a flat dataset\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "#shffule these windows for fast traning\n",
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRsXN4edjZS4"
      },
      "source": [
        "# Loading the Data and Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI4dqKlZjbBA",
        "outputId": "ed509c97-264e-419f-ebe5-5d7469093aa0"
      },
      "source": [
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwDG4bTXlXOv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfXmVIrhnxhe"
      },
      "source": [
        "# Preprocessing the Input Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeWnLe8XubSi"
      },
      "source": [
        "### create one-hot vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUk3cQznn63n"
      },
      "source": [
        "# create one-hot vector by numpy\n",
        "#ref: https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=qbxlvnf11&logNo=221528102803\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "flower_list = ['Cherry Blossom', 'Dandelion', 'korean rosebay']\n",
        "print(flower_list)\n",
        "\n",
        "values = []\n",
        "for x in range(len(flower_list)):\n",
        "    values.append(x)\n",
        "print(values)\n",
        "\n",
        "values_len = len(values)\n",
        "print(values_len)\n",
        "\n",
        "encoding = np.eye(values_len)[values]\n",
        "print(encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Dgl2I_SoNlE",
        "outputId": "ae632fd9-9aac-4969-ba3b-87f9a7a7f2c8"
      },
      "source": [
        "#create a lookup table\n",
        "#ref : Hands-on p431\n",
        "category_list = [\"one\", \"two\", \"three\", \"four\"]\n",
        "indices = tf.range(len(category_list), dtype=tf.int64)\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(category_list, indices) # create an initializer for the lookup table\n",
        "num_oov_buckets = 2 #the number of out-of-vocabulary (oov) buckets\n",
        "table = tf.lookup.StaticVocabularyTable(table_init, num_oov-buckets) #create the lookup table"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfNOFSzp6Gi"
      },
      "source": [
        "ex_input = tf.constant([\"three\", \"two\", \"extra\"])\n",
        "ex_indices = table.lookup(ex_input)\n",
        "ex_one_hot = tf.one_hot(ex_indices, depth=len(category_list) + num_oov_buckets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqX0GR3zoNUm"
      },
      "source": [
        "# Building and Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bueut_dfsh4C"
      },
      "source": [
        "#LSTM layer\n",
        "model = tf.kears.models.Sequential([\n",
        "    tf.keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    tf.keras.layers.LSTM(tf.keras.LSTMCell(20),\n",
        "    tf.keras.layers.TimeDistriuted(tf.keras.layers.Dense(10))                                       \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GulJTvwquaE"
      },
      "source": [
        "#the general-purpose keras.layers.RNN layers\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.RNN(tf.keras.LSTMCell(20), return_sequences=True, input_shape=[None,1]),\n",
        "    keras.layers.RNN(tf.keras.LSTMCell(20), return_sequences=True),\n",
        "    keras.layers.TimeDistriuted(tf.keras.layers.Dense(10))                                \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaCzf5Ynq008"
      },
      "source": [
        "model.compile(loss=, optimizer='adam')\n",
        "history = model.fit(dataset, epcohs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMBjeV0yqrX_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF90GSfsq9kR",
        "outputId": "dcdd9d53-0000-4d90-9aed-a99579d65267"
      },
      "source": [
        "abc = 'qwer'\n",
        "type([abc])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ttuN7g6vx-VE",
        "outputId": "b686f2e4-87f1-43dc-ba77-91a67a4fcfaa"
      },
      "source": [
        "[abc][0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'qwer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcOIqUqix0PB",
        "outputId": "9eddf463-478f-414b-bb00-f00275d1eeca"
      },
      "source": [
        "type(abc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}